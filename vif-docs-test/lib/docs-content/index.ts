/**
 * Auto-generated docs content from markdown sources
 * Generated by: dewey create
 * Generated at: 2026-01-19T14:00:41.953Z
 */

export const overview = `# Overview

**vif** is a screen capture and browser automation toolkit for macOS, designed specifically for AI agents and LLMs.

## What is vif?

vif combines three capabilities:

1. **Screen Capture** - Screenshots, video recording, and GIF creation using native macOS tools
2. **Browser Automation** - Chrome automation via Chrome DevTools Protocol (CDP)
3. **Demo Automation** - Visual overlays (cursor, labels, keys) for recording polished demos

Everything is designed to work with AI agents: predictable CLI output, MCP tools for Claude Code, and a Stagehand-style API for programmatic control.

## Key Features

### Screen Capture
- Screenshot windows, regions, or fullscreen
- Video recording with optional audio
- Convert to GIF, optimize for web
- Take management (versioned screenshots)

### Browser Automation
- Navigate, click, type, scroll in Chrome
- Extract structured data from pages
- Observe DOM elements with accessibility info
- Stagehand-compatible API (\`vif.observe()\`, \`vif.act()\`)

### Demo Recording
- Animated cursor overlay
- Keyboard shortcut display
- Text labels/teleprompter
- Viewport highlighting
- Backdrop dimming

### AI Agent Integration
- MCP server for Claude Code (\`vif-mcp\`)
- CLI designed for LLM tool use (\`vif\`, \`vif-ctl\`)
- Scene DSL for declarative automation

## Architecture

\`\`\`
┌─────────────────────────────────────────────────────────┐
│                    Your AI Agent                         │
│                (Claude Code, etc.)                       │
└───────────────────────┬─────────────────────────────────┘
                        │ MCP / CLI
┌───────────────────────┴─────────────────────────────────┐
│                      vif                                 │
├─────────────────┬─────────────────┬─────────────────────┤
│  Screen Capture │ Browser (CDP)   │   Demo Overlays     │
│  - screencapture│ - navigate      │   - cursor          │
│  - ffmpeg       │ - click/type    │   - labels          │
│  - native APIs  │ - extract       │   - keys            │
└─────────────────┴─────────────────┴─────────────────────┘
\`\`\`

## Quick Links

- [Quickstart](./quickstart.md) - Get started in 5 minutes
- [Browser Automation](./browser.md) - Chrome automation via CDP
- [Scene DSL](./scenes.md) - Declarative demo automation
- [MCP Tools](./mcp.md) - Claude Code integration`

export const quickstart = `# Quickstart

Get up and running with vif in under 5 minutes.

## Prerequisites

- **macOS** (uses native screencapture, Accessibility API)
- **Node.js 18+**
- **Xcode Command Line Tools**: \`xcode-select --install\`
- **ffmpeg** (optional, for video processing): \`brew install ffmpeg\`

### Required Permissions

Grant in **System Settings > Privacy & Security**:

| Permission | Required For |
|------------|--------------|
| Screen Recording | Screenshots, video capture |
| Accessibility | Mouse/keyboard automation |

## Installation

\`\`\`bash
# Install via pnpm
pnpm add @arach/vif

# Or globally for CLI access
pnpm add -g @arach/vif
\`\`\`

## Screen Capture

\`\`\`bash
# Screenshot fullscreen
vif shot screenshot.png

# Screenshot an app window
vif shot --app Safari safari.png

# Record video (Ctrl+C to stop)
vif record demo.mp4

# Convert to GIF
vif gif demo.mp4 demo.gif --width 600 --fps 15
\`\`\`

## Browser Automation

Control Chrome via CDP (Chrome DevTools Protocol):

\`\`\`typescript
import { createVif } from '@arach/vif'

const vif = createVif()

// Launch Chrome and navigate
await vif.launch('https://news.ycombinator.com')

// Find elements on the page
const elements = await vif.observe({ format: 'clickable-only' })
console.log(elements)  // [{ selector: "a.storylink", text: "Show HN: ..." }, ...]

// Click an element
await vif.click('a.storylink:first-child')

// Type into an input
await vif.type('input[name="q"]', 'search query')

// Extract data
const data = await vif.extract({
  title: 'title',
  links: 'a.storylink'
})

await vif.close()
\`\`\`

## Demo Overlays

Show visual overlays for demo recordings:

\`\`\`bash
# Start the automation server (required for overlays)
vif serve

# In another terminal:
vif-ctl cursor show                     # Show animated cursor
vif-ctl cursor move 500 300 0.5         # Move with animation
vif-ctl label show "Recording demo"     # Show text label
vif-ctl keys show cmd shift p           # Show keyboard shortcut
vif-ctl backdrop on                     # Dim background
vif-ctl stage clear                     # Clear all overlays
\`\`\`

## MCP Server (Claude Code)

Connect vif to Claude Code via MCP:

\`\`\`bash
vif-mcp  # Start MCP server
\`\`\`

Add to Claude Code's MCP config:
\`\`\`json
{
  "mcpServers": {
    "vif": {
      "command": "vif-mcp"
    }
  }
}
\`\`\`

Then ask Claude to use vif tools:
- "Take a screenshot of Safari"
- "Navigate Chrome to github.com and click Sign in"
- "Show the cursor at 500, 300"

## Scene DSL

Define demo sequences in YAML:

\`\`\`yaml
scene:
  name: My Demo
  mode: draft

sequence:
  - wait: 500ms
  - cursor.show: {}
  - cursor.moveTo: { x: 500, y: 300 }
  - cursor.click: {}
  - label.show: "Welcome!"
  - wait: 2s
  - stage.clear: {}
\`\`\`

Run:
\`\`\`bash
vif play demo.yaml              # Execute scene
vif play --validate demo.yaml   # Validate only
vif play --watch demo.yaml      # Re-run on changes
\`\`\`

## Next Steps

- [Browser Automation](./browser.md) - Full CDP API reference
- [Scene DSL](./scenes.md) - Complete scene syntax
- [MCP Tools](./mcp.md) - All available MCP tools`

export const browser = `# Browser Automation

vif provides Chrome automation via the Chrome DevTools Protocol (CDP). The API is inspired by Stagehand but runs locally without external AI inference costs.

## Quick Example

\`\`\`typescript
import { createVif } from '@arach/vif'

const vif = createVif()
await vif.launch('https://news.ycombinator.com')

// Find elements on page
const { elements } = await vif.observe()
console.log(elements)
// [{ nodeId: 42, tag: 'a', label: 'Hacker News', text: '...', bounds: {...} }, ...]

// Click an element
await vif.click('a.storylink:first-child')

// Type into input
await vif.type('input[name="q"]', 'search query')

// Extract data
const data = await vif.extract({
  title: 'title',
  links: 'a.storylink'
})

await vif.close()
\`\`\`

## The Vif Class

### Constructor Options

\`\`\`typescript
interface VifOptions {
  /** Chrome debugging port (default: 9222) */
  port?: number;
  /** Run in headless mode */
  headless?: boolean;
  /** Additional Chrome flags */
  chromeFlags?: string[];
}

const vif = new Vif({
  port: 9222,
  headless: true,
  chromeFlags: ['--disable-gpu']
})
\`\`\`

### Lifecycle Methods

\`\`\`typescript
// Launch Chrome and connect
await vif.launch('https://example.com')

// Or connect to existing Chrome
await vif.connect()

// Check connection
vif.isConnected()  // boolean

// Close browser
await vif.close()
\`\`\`

### Navigation

\`\`\`typescript
// Navigate to URL
await vif.navigate('https://example.com')

// History navigation
await vif.back()
await vif.forward()
await vif.reload()

// Get current URL
const currentUrl = await vif.url()
\`\`\`

## Observation (Stagehand-style)

The \`observe()\` method returns interactive elements on the page. Unlike Stagehand, vif doesn't call an external LLM - it returns structured data that you (or Claude) can interpret.

\`\`\`typescript
// Get all clickable elements
const { elements } = await vif.observe()

// Filter by selector
const { elements } = await vif.observe({ selector: 'button' })

// Elements include:
interface ClickableElement {
  nodeId: number;      // CDP node ID (use with clickNode)
  tag: string;         // Element tag name
  role: string;        // ARIA role
  label: string;       // Accessible name
  text: string;        // Text content
  selector: string;    // CSS selector
  bounds: {
    x: number;
    y: number;
    width: number;
    height: number;
    centerX: number;
    centerY: number;
  };
}
\`\`\`

### Accessibility Tree

\`\`\`typescript
// Get full accessibility tree
const tree = await vif.accessibility()

interface AccessibilityNode {
  nodeId: number;
  role: string;
  name: string;
  value?: string;
  description?: string;
  children?: AccessibilityNode[];
}
\`\`\`

## Actions

### Click

\`\`\`typescript
// Click by CSS selector
await vif.click('button.submit')

// Click by node ID (from observe)
const { elements } = await vif.observe()
await vif.clickNode(elements[0].nodeId)

// Natural language click (fuzzy match)
await vif.act('click the submit button')
await vif.act('click Login')
await vif.act('tap on Sign Up')
\`\`\`

### Type

\`\`\`typescript
// Type into element
await vif.type('input[name="email"]', 'user@example.com')

// With options
await vif.type('input[name="email"]', 'user@example.com', {
  clear: true,    // Clear existing text first
  delay: 50       // Delay between keystrokes (ms)
})

// Type into focused element
await vif.typeText('Hello world')
\`\`\`

### Keyboard

\`\`\`typescript
// Press single key
await vif.press('Enter')
await vif.press('Tab')
await vif.press('Escape')

// Keyboard shortcut
await vif.press(['Control', 'a'])  // Select all
await vif.press(['Meta', 'c'])     // Copy (Cmd+C on Mac)
\`\`\`

### Mouse

\`\`\`typescript
// Hover over element
await vif.hover('button.menu')

// Scroll
await vif.scroll('down')
await vif.scroll('up', { amount: 500 })
await vif.scroll('down', { selector: '.scrollable-container' })
\`\`\`

## Data Extraction

\`\`\`typescript
// Extract text by selectors
const data = await vif.extract({
  title: 'h1',
  description: 'meta[name="description"]',
  links: 'a.nav-link'  // Multiple matches return array
})
// { title: 'Page Title', description: '...', links: ['Home', 'About', 'Contact'] }

// Get text of single element
const heading = await vif.getText('h1')

// Get attribute value
const href = await vif.getAttribute('a.main-link', 'href')
\`\`\`

## Screenshots

\`\`\`typescript
// Screenshot to temp file
const path = await vif.screenshot()

// Save to specific path
await vif.screenshot({ path: './screenshot.png' })

// Full page screenshot
await vif.screenshot({ fullPage: true, path: './full.png' })

// Element screenshot
await vif.screenshot({ selector: '.hero-section', path: './hero.png' })

// Different formats
await vif.screenshot({ format: 'jpeg', path: './shot.jpg' })
await vif.screenshot({ format: 'webp', path: './shot.webp' })
\`\`\`

## Waiting

\`\`\`typescript
// Wait for element to appear
await vif.waitForSelector('.dynamic-content')

// With timeout
await vif.waitForSelector('.modal', 5000)  // 5 seconds

// Wait for navigation
await vif.waitForNavigation()

// Fixed delay
await vif.wait(1000)  // 1 second
\`\`\`

## JavaScript Evaluation

\`\`\`typescript
// Execute JS in page context
const title = await vif.evaluate('document.title')

const dimensions = await vif.evaluate(\`({
  width: window.innerWidth,
  height: window.innerHeight
})\`)
\`\`\`

## How It Differs from Stagehand

| Feature | Stagehand | vif |
|---------|-----------|-----|
| AI inference | External API (paid) | None (local) |
| \`observe()\` | AI interprets instruction | Returns element list |
| \`act()\` | AI picks element | Fuzzy text matching |
| \`extract()\` | Schema-based + AI | CSS selectors |
| Use case | AI-autonomous browsing | Claude-assisted automation |

**vif's approach**: Instead of paying for AI inference on every action, vif returns structured data that Claude (already running in Claude Code) can interpret. This is "Claude-in-the-loop" automation.

## MCP Tools

The browser automation is also available as MCP tools:

- \`vif_browser_launch\` - Launch Chrome
- \`vif_browser_navigate\` - Navigate to URL
- \`vif_browser_click\` - Click element
- \`vif_browser_type\` - Type text
- \`vif_browser_scroll\` - Scroll page
- \`vif_browser_extract\` - Extract data
- \`vif_browser_press\` - Press key
- \`vif_browser_hover\` - Hover over element
- \`vif_observe\` - Get page elements
- \`vif_click_element\` - Click by node ID
- \`vif_screenshot\` - Take screenshot
- \`vif_browser_close\` - Close browser

See [MCP Tools](./mcp.md) for full documentation.`

export const scenes = `# Scene DSL

Define demo sequences declaratively in YAML. Scenes automate cursor movement, clicks, typing, overlays, and recording.

## Quick Example

\`\`\`yaml
scene:
  name: My App Demo
  mode: draft    # 'draft' = overwrite ~/.vif/draft.mp4, 'final' = timestamped

app:
  name: Safari
  window:
    width: 1200
    height: 800

stage:
  backdrop: true
  viewport:
    padding: 10

sequence:
  - wait: 500ms
  - record: start
  - cursor.show: {}
  - cursor.moveTo: { x: 500, y: 300, duration: 0.3 }
  - cursor.click: {}
  - label.show: "Welcome to the demo"
  - wait: 2s
  - record: stop
\`\`\`

Run with:
\`\`\`bash
vif play demo.yaml              # Execute scene
vif play --validate demo.yaml   # Validate without running
vif play --watch demo.yaml      # Re-run on file changes
vif play --verbose demo.yaml    # Show detailed logging
\`\`\`

## Scene Structure

### \`scene\` - Metadata

\`\`\`yaml
scene:
  name: Demo Name           # Display name
  mode: draft               # draft | final
  output: my-recording      # Custom output filename (final mode only)
\`\`\`

### \`app\` - Target Application

\`\`\`yaml
app:
  name: Safari              # macOS app name
  window:
    width: 1200             # Desired window width
    height: 800             # Desired window height
\`\`\`

The app window will be centered on screen at the specified size.

### \`stage\` - Visual Setup

\`\`\`yaml
stage:
  backdrop: true            # Dim everything outside viewport
  viewport:
    padding: 10             # Padding around app window
\`\`\`

## Actions

### Cursor Actions

\`\`\`yaml
# Show/hide cursor overlay
- cursor.show: {}
- cursor.hide: {}

# Move cursor (coordinates relative to app window)
- cursor.moveTo: { x: 500, y: 300, duration: 0.3 }

# Click at current position
- cursor.click: {}

# Combined click action
- click: { x: 500, y: 300 }
- click: sidebar.home       # Named target (see Views)
\`\`\`

### Timing

\`\`\`yaml
- wait: 500ms
- wait: 2s
- wait: 1.5s
\`\`\`

### Recording

\`\`\`yaml
- record: start
# ... actions ...
- record: stop
\`\`\`

In \`draft\` mode, recording saves to \`~/.vif/draft.mp4\` (overwritten each run).
In \`final\` mode, recordings are timestamped and saved to \`~/.vif/recordings/\`.

### Labels

\`\`\`yaml
# Show label at top/bottom of screen
- label.show: "Welcome to the demo"
- label.update: "New text"
- label.hide: {}

# With position
- label:
    text: "Caption here"
    position: bottom
\`\`\`

### Keyboard

\`\`\`yaml
# Show keyboard shortcut overlay
- keys.show:
    keys: ["cmd", "shift", "p"]
    press: true              # Animate keypress

- keys.hide: {}

# Actually press keys (sends to app)
- input.keys: ["cmd", "c"]
\`\`\`

### Typing

\`\`\`yaml
# Visual typing overlay (doesn't send keys)
- typer.type:
    text: "Hello world"
    style: default           # default | terminal | code
    delay: 0.05              # Seconds between characters

- typer.hide: {}

# Actual keyboard typing (sends to app)
- input.type:
    text: "Hello world"
    delay: 0.03
\`\`\`

### Audio

\`\`\`yaml
# Play audio through virtual microphone
- voice.play: audio/intro.mp3
- voice.play:
    file: audio/intro.mp3
    wait: true               # Wait for playback to finish

- voice.stop: {}

# Multi-channel audio
- audio.play:
    file: music/background.mp3
    channel: 2
    fadeIn: 1s
    loop: true

- audio.volume:
    channel: 2
    volume: 0.5
    duration: 500ms

- audio.stop:
    channel: 2
    fadeOut: 2s
\`\`\`

### Navigation

\`\`\`yaml
# Navigate through multiple items
- navigate:
    through: sidebar
    items: [home, settings, profile]
    wait: 400ms              # Wait between clicks
\`\`\`

## Views

Define reusable click targets within your scene:

\`\`\`yaml
views:
  sidebar:
    region: { x: 0, width: 200 }
    items:
      - home: { y: 100 }
      - settings: { y: 140 }
      - profile: { y: 180 }

  toolbar:
    positions:
      save: { x: 100, y: 50 }
      undo: { x: 140, y: 50 }

sequence:
  - click: sidebar.home
  - click: toolbar.save
\`\`\`

## Labels Definition

Define reusable labels:

\`\`\`yaml
labels:
  intro:
    text: "Welcome to the demo"
    position: top

  outro:
    text: "Thanks for watching!"
    position: bottom

sequence:
  - label: intro
  - wait: 2s
  - label: outro
\`\`\`

## VifTargets SDK Integration

For first-party apps, integrate the VifTargets SDK to expose semantic targets:

\`\`\`swift
// In your SwiftUI app
Button("Submit") { ... }
  .vifTarget("submit-btn")
\`\`\`

Then reference in scenes:
\`\`\`yaml
- click: submit-btn    # Resolved via SDK at runtime
\`\`\`

The SDK exposes targets via HTTP on port 7851, which vif queries during scene execution.

## Audio Configuration

Configure multi-channel audio mixing:

\`\`\`yaml
audio:
  channels:
    1:  # Voice channel
      output: virtual-mic    # Route to BlackHole for app input
      volume: 1.0
    2:  # Music channel
      output: post-mix       # Mix in post-processing
      volume: 0.3

sequence:
  - audio.play:
      file: voice/intro.mp3
      channel: 1
  - audio.play:
      file: music/background.mp3
      channel: 2
      loop: true
\`\`\`

## Full Example

\`\`\`yaml
scene:
  name: Talkie Demo
  mode: draft

app:
  name: Talkie
  window:
    width: 1280
    height: 800

stage:
  backdrop: true
  viewport:
    padding: 10

views:
  sidebar:
    region: { x: 0, width: 200 }
    items:
      - voices: { y: 100 }
      - settings: { y: 300 }

labels:
  intro:
    text: "Welcome to Talkie"
    position: top

sequence:
  - wait: 500ms
  - record: start
  - cursor.show: {}
  - label: intro
  - wait: 1s

  - cursor.moveTo: { x: 400, y: 300, duration: 0.4 }
  - cursor.click: {}

  - input.type:
      text: "Hello, this is a demo"
      delay: 0.03

  - keys.show:
      keys: ["cmd", "return"]
      press: true
  - input.keys: ["cmd", "return"]
  - wait: 500ms
  - keys.hide: {}

  - navigate:
      through: sidebar
      items: [voices, settings]
      wait: 800ms

  - label.hide: {}
  - cursor.hide: {}
  - record: stop
\`\`\`

## CLI Reference

\`\`\`bash
vif play <scene.yaml>           # Run scene
vif play --validate <scene>     # Validate only
vif play --watch <scene>        # Watch for changes
vif play --verbose <scene>      # Detailed logging
vif play --dry-run <scene>      # Show actions without executing
\`\`\``

export const mcp = `# MCP Tools

vif exposes all its capabilities as MCP (Model Context Protocol) tools, allowing Claude Code to control screen capture, overlays, and browser automation directly.

## Setup

Start the MCP server:
\`\`\`bash
vif-mcp
\`\`\`

Add to Claude Code's MCP configuration (\`~/.claude/settings.json\`):
\`\`\`json
{
  "mcpServers": {
    "vif": {
      "command": "vif-mcp"
    }
  }
}
\`\`\`

**Note:** Demo overlay tools require the vif server running (\`vif serve\`).

## Tool Categories

### Cursor Overlay Tools

| Tool | Description |
|------|-------------|
| \`vif_cursor_show\` | Show the animated cursor overlay |
| \`vif_cursor_hide\` | Hide the cursor overlay |
| \`vif_cursor_move\` | Move cursor to position with animation |
| \`vif_cursor_click\` | Perform click animation at current position |

**Example:**
\`\`\`
Claude, show the cursor at position 500, 300 and click
\`\`\`

### Label/Caption Tools

| Tool | Description |
|------|-------------|
| \`vif_label_show\` | Show a text label overlay |
| \`vif_label_update\` | Update the label text |
| \`vif_label_hide\` | Hide the label |

**Parameters for \`vif_label_show\`:**
- \`text\` (required): Text to display
- \`position\`: "top" or "bottom" (default: "top")

### Backdrop/Stage Tools

| Tool | Description |
|------|-------------|
| \`vif_backdrop_show\` | Dim everything outside viewport |
| \`vif_backdrop_hide\` | Remove backdrop dimming |
| \`vif_stage_center\` | Center an app window on screen |
| \`vif_stage_clear\` | Clear all overlays |

**Parameters for \`vif_stage_center\`:**
- \`app\` (required): App name (e.g., "Safari", "Finder")
- \`width\`: Window width
- \`height\`: Window height

### Viewport Tools

| Tool | Description |
|------|-------------|
| \`vif_viewport_set\` | Define the visible region |
| \`vif_viewport_show\` | Show viewport mask |
| \`vif_viewport_hide\` | Hide viewport mask |

**Parameters for \`vif_viewport_set\`:**
- \`x\`, \`y\`, \`width\`, \`height\` (all required)

### Keyboard Overlay Tools

| Tool | Description |
|------|-------------|
| \`vif_keys_show\` | Show keyboard shortcut overlay |
| \`vif_keys_hide\` | Hide keyboard overlay |

**Parameters for \`vif_keys_show\`:**
- \`keys\` (required): Array of keys, e.g., \`["cmd", "shift", "p"]\`
- \`press\`: Animate as keypress (boolean)

### Typer Overlay Tools

| Tool | Description |
|------|-------------|
| \`vif_typer_type\` | Show animated typing overlay |
| \`vif_typer_hide\` | Hide typer overlay |

**Parameters for \`vif_typer_type\`:**
- \`text\` (required): Text to type
- \`style\`: "default", "terminal", or "code"
- \`delay\`: Seconds between characters (default: 0.05)

### Recording Tools

| Tool | Description |
|------|-------------|
| \`vif_record_indicator\` | Show/hide recording indicator |

**Parameters:**
- \`show\` (required): Boolean

## Browser Automation Tools

These tools control Chrome via CDP (Chrome DevTools Protocol).

| Tool | Description |
|------|-------------|
| \`vif_browser_launch\` | Launch Chrome and connect |
| \`vif_browser_navigate\` | Navigate to URL |
| \`vif_browser_click\` | Click element by CSS selector |
| \`vif_browser_type\` | Type text into element |
| \`vif_browser_scroll\` | Scroll page or element |
| \`vif_browser_extract\` | Extract data using selectors |
| \`vif_browser_press\` | Press key or shortcut |
| \`vif_browser_hover\` | Hover over element |
| \`vif_observe\` | Get interactive elements on page |
| \`vif_click_element\` | Click by node ID (from observe) |
| \`vif_screenshot\` | Take browser screenshot |
| \`vif_browser_close\` | Close browser connection |

### Browser Tool Parameters

**\`vif_browser_launch\`**
- \`url\` (optional): Initial URL to navigate to
- \`headless\` (optional): Run in headless mode

**\`vif_browser_navigate\`**
- \`url\` (required): URL to navigate to

**\`vif_browser_click\`**
- \`selector\` (required): CSS selector

**\`vif_browser_type\`**
- \`selector\` (required): CSS selector
- \`text\` (required): Text to type
- \`clear\` (optional): Clear existing text first
- \`delay\` (optional): Delay between keystrokes (ms)

**\`vif_browser_scroll\`**
- \`direction\` (required): "up", "down", "left", or "right"
- \`amount\` (optional): Pixels to scroll
- \`selector\` (optional): Element to scroll

**\`vif_browser_extract\`**
- \`selectors\` (required): Object mapping names to CSS selectors
  \`\`\`json
  { "title": "h1", "links": "a.nav-link" }
  \`\`\`

**\`vif_observe\`**
- \`format\` (optional): "clickable" (default), "accessibility", or "full"
- \`selector\` (optional): Filter to specific selector

**\`vif_screenshot\`**
- \`path\` (optional): Save path
- \`fullPage\` (optional): Capture full page
- \`selector\` (optional): Capture specific element

## Example Conversations

### Demo Recording

\`\`\`
User: Record a demo of our app's new feature

Claude: I'll set up the stage and record. Let me:
1. Center the app window
2. Show the backdrop
3. Record the demo with cursor and labels

[Uses vif_stage_center, vif_backdrop_show, vif_cursor_show,
vif_cursor_move, vif_cursor_click, vif_label_show, etc.]
\`\`\`

### Web Scraping

\`\`\`
User: Go to Hacker News and get the top 5 story titles

Claude: I'll navigate to Hacker News and extract the titles.

[Uses vif_browser_launch, vif_browser_navigate, vif_browser_extract]

Here are the top 5 stories:
1. Show HN: ...
2. ...
\`\`\`

### Automated Testing

\`\`\`
User: Test the login flow on our staging site

Claude: I'll test the login flow.

[Uses vif_browser_launch with staging URL]
[Uses vif_observe to find login form]
[Uses vif_browser_type for email and password]
[Uses vif_browser_click to submit]
[Uses vif_screenshot to capture result]

Login successful. Screenshot saved.
\`\`\`

## Tool Availability

| Tool Category | Requires \`vif serve\` | Requires Chrome |
|--------------|---------------------|-----------------|
| Cursor/Label/Stage | Yes | No |
| Viewport/Backdrop | Yes | No |
| Keys/Typer | Yes | No |
| Browser tools | No | Yes |

## Error Handling

Tools return error messages when:
- \`vif serve\` is not running (for overlay tools)
- Chrome is not available (for browser tools)
- Element not found (for click/type actions)
- Navigation timeout

Claude should handle these gracefully and inform the user.`

export const audio = `# Multi-Channel Audio

Vif supports multi-channel audio with real-time playback and post-processing mixing.

## How It Works

- **Channel 1** (narration): Plays through BlackHole virtual mic in real-time, captured by screen recording
- **Other channels**: Recorded to a timeline, mixed with FFmpeg after recording completes

This means narration syncs perfectly with your demo, while music and SFX are layered in post.

## Configuration

Define channels in the \`audio:\` block:

\`\`\`yaml
audio:
  channels:
    1:
      role: narration
      output: virtual-mic   # Real-time through BlackHole
      volume: 1.0
    2:
      role: music
      output: post-only     # Mixed in post-processing
      volume: 0.3
    3:
      role: sfx
      output: post-only
      volume: 0.7
\`\`\`

### Channel Options

| Option | Values | Description |
|--------|--------|-------------|
| \`role\` | \`narration\`, \`music\`, \`sfx\`, \`ambient\`, \`custom\` | Label for the channel |
| \`output\` | \`virtual-mic\`, \`post-only\`, \`monitor\`, \`both\` | Where audio plays |
| \`volume\` | 0.0 - 1.0 | Channel volume |
| \`pan\` | -1.0 to 1.0 | Stereo position (left to right) |

## Actions

### audio.play

Play audio on a channel:

\`\`\`yaml
- audio.play:
    file: audio/narration.mp3
    channel: 1
    wait: true          # Wait for playback to finish
    fadeIn: 500ms
    fadeOut: 1s
    loop: false
\`\`\`

Playing on the same channel auto-crossfades:

\`\`\`yaml
# Track A is playing on channel 2...
- audio.play:
    file: audio/track-b.mp3
    channel: 2
    fadeIn: 2s          # Track A fades out, Track B fades in
\`\`\`

### audio.stop

Stop a channel (or all channels):

\`\`\`yaml
# Stop specific channel with fade
- audio.stop:
    channel: 2
    fadeOut: 2s

# Stop all audio
- audio.stop: true
\`\`\`

### audio.volume

Animate volume changes:

\`\`\`yaml
- audio.volume:
    channel: 2
    volume: 0.1         # Duck the music
    duration: 500ms     # Animate over half a second
\`\`\`

## Pre-loaded Tracks

Start tracks at specific times in the scene:

\`\`\`yaml
audio:
  channels:
    2:
      role: music
      output: post-only
      volume: 0.3
  tracks:
    - file: audio/intro-music.mp3
      channel: 2
      startTime: 0
      fadeIn: 2s
      fadeOut: 3s
\`\`\`

## Example: Demo with Music + Narration

\`\`\`yaml
scene:
  name: Product Demo
  output: demo-final

audio:
  channels:
    1:
      role: narration
      output: virtual-mic
    2:
      role: music
      output: post-only
      volume: 0.25

sequence:
  - record: start

  # Background music starts
  - audio.play:
      file: audio/upbeat-bg.mp3
      channel: 2
      fadeIn: 1s
      loop: true

  # Narration plays through virtual mic
  - audio.play:
      file: audio/intro.mp3
      channel: 1

  # Duck music during important narration
  - audio.volume:
      channel: 2
      volume: 0.1
      duration: 300ms

  - audio.play:
      file: audio/key-feature.mp3
      channel: 1

  # Bring music back
  - audio.volume:
      channel: 2
      volume: 0.25
      duration: 300ms

  - wait: 2s

  # Fade out music
  - audio.stop:
      channel: 2
      fadeOut: 2s

  - record: stop
\`\`\`

## Requirements

- **BlackHole** (2ch) for virtual mic routing
- **FFmpeg** for post-processing audio mix
- Audio files: MP3, WAV, M4A supported`

export const talkie_integration = `# Talkie Integration: Mic Selection for Ephemeral Capture

## Overview

This adds mic selection support to EphemeralTranscriber, allowing it to use the user's selected microphone instead of always using the system default.

## Files to Modify

### 1. \`macOS/Talkie/Services/EphemeralTranscriber.swift\`

Add imports at the top:
\`\`\`swift
import CoreAudio
import AudioToolbox
\`\`\`

Add this method to the \`EphemeralTranscriber\` class:

\`\`\`swift
/// Configure the audio engine to use the user's selected input device
private func configureInputDevice(engine: AVAudioEngine) {
    let audioManager = AudioDeviceManager.shared
    audioManager.ensureInitialized()

    // Use the user's selected device from settings
    let selectedID = audioManager.selectedDeviceID
    guard selectedID != 0 else {
        logger.debug("Using system default audio input")
        return
    }

    // Get the audio unit from the input node
    guard let audioUnit = engine.inputNode.audioUnit else {
        logger.warning("Could not get audio unit from input node")
        return
    }

    // Set the input device to match user's selection
    var deviceID = selectedID
    let status = AudioUnitSetProperty(
        audioUnit,
        kAudioOutputUnitProperty_CurrentDevice,
        kAudioUnitScope_Global,
        0,
        &deviceID,
        UInt32(MemoryLayout<AudioDeviceID>.size)
    )

    if status == noErr {
        let deviceName = audioManager.inputDevices.first(where: { \$0.id == selectedID })?.name ?? "Unknown"
        logger.info("Using selected mic: \\(deviceName)")
    } else {
        logger.error("Failed to set audio input device: \\(status)")
    }
}
\`\`\`

In the \`startCapture()\` method, call \`configureInputDevice\` after creating the engine:

\`\`\`swift
// Create audio engine
let engine = AVAudioEngine()
self.audioEngine = engine

// Configure input device (use selected mic from settings)
configureInputDevice(engine: engine)

let inputNode = engine.inputNode
// ... rest of the method
\`\`\`

## How It Works

1. \`AudioDeviceManager.shared.selectedDeviceID\` returns the user's mic selection from settings
2. We use \`AudioUnitSetProperty\` to configure AVAudioEngine's input node to use that specific device
3. If no device is selected (ID = 0), we fall back to system default

## Benefits

- EphemeralTranscriber now respects the mic picker in settings
- Works with any audio input device (including virtual devices like BlackHole)
- No special demo mode code needed - just select the mic you want to use`

export const docs: Record<string, string> = {
  'overview': overview,
  'quickstart': quickstart,
  'browser': browser,
  'scenes': scenes,
  'mcp': mcp,
  'audio': audio,
  'talkie-integration': talkie_integration,
}
